"""
Z-Image Img2Img Training Script

åŸºäº train_zimage_v2.py æ‰©å±•çš„å›¾åƒè½¬æ¢è®­ç»ƒè„šæœ¬ã€‚
æ”¯æŒä½¿ç”¨æºå›¾åƒå’Œç›®æ ‡å›¾åƒå¯¹è¿›è¡Œè®­ç»ƒã€‚

æ•°æ®é›†æ ¼å¼:
    source/    - æºå›¾åƒ (è¾“å…¥)
    target/    - ç›®æ ‡å›¾åƒ (æœŸæœ›è¾“å‡º)
    metadata.jsonl - åŒ…å« caption å’Œå¯é€‰çš„ strength_hint

å…³é”®ç‰¹æ€§:
- ç»§æ‰¿ AC-RF è®­ç»ƒæ¡†æ¶
- Strength é‡‡æ ·ç­–ç•¥ï¼šè®­ç»ƒæ—¶éšæœºé‡‡æ · strength
- ä¸ Img2Img Pipeline è¡Œä¸ºä¸€è‡´
"""

import os
import sys
import argparse
import logging
import signal
from pathlib import Path

# Add src to path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), "../src"))

import torch
import torch.nn.functional as F
from tqdm import tqdm
from accelerate import Accelerator
from accelerate.utils import set_seed
from diffusers.optimization import get_scheduler

# Local imports
from zimage_trainer.networks.lora import LoRANetwork, ZIMAGE_TARGET_NAMES
from zimage_trainer.acrf_trainer import ACRFTrainer

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Interrupt handler
_interrupted = False

def signal_handler(signum, frame):
    global _interrupted
    _interrupted = True
    logger.info("[INTERRUPT] Training will stop after current step...")

signal.signal(signal.SIGINT, signal_handler)
signal.signal(signal.SIGTERM, signal_handler)


def parse_args():
    parser = argparse.ArgumentParser(description="Z-Image Img2Img Training")
    parser.add_argument("--config", type=str, required=True, help="TOML config path")
    
    # Model paths
    parser.add_argument("--dit", type=str, default=None, help="Transformer æ¨¡å‹è·¯å¾„")
    parser.add_argument("--vae", type=str, default=None, help="VAE æ¨¡å‹è·¯å¾„")
    
    # Training params
    parser.add_argument("--output_dir", type=str, default="output")
    parser.add_argument("--output_name", type=str, default="zimage_img2img")
    parser.add_argument("--seed", type=int, default=42)
    parser.add_argument("--num_train_epochs", type=int, default=10)
    parser.add_argument("--learning_rate", type=float, default=1e-4)
    parser.add_argument("--gradient_accumulation_steps", type=int, default=1)
    parser.add_argument("--max_grad_norm", type=float, default=1.0)
    parser.add_argument("--save_every_n_epochs", type=int, default=1)
    parser.add_argument("--gradient_checkpointing", type=bool, default=True)
    
    # LoRA
    parser.add_argument("--network_dim", type=int, default=16)
    parser.add_argument("--network_alpha", type=float, default=16)
    parser.add_argument("--resume_lora", type=str, default=None)
    
    # Img2Img specific
    parser.add_argument("--strength_min", type=float, default=0.3,
        help="Strength æœ€å°å€¼ (è®­ç»ƒæ—¶éšæœºé‡‡æ ·)")
    parser.add_argument("--strength_max", type=float, default=0.9,
        help="Strength æœ€å¤§å€¼")
    
    # AC-RF / Turbo
    parser.add_argument("--turbo_steps", type=int, default=10)
    parser.add_argument("--shift", type=float, default=3.0)
    parser.add_argument("--use_dynamic_shift", type=bool, default=True)
    parser.add_argument("--jitter_scale", type=float, default=0.02)
    parser.add_argument("--enable_turbo", type=bool, default=True)
    
    # Loss weights
    parser.add_argument("--lambda_l1", type=float, default=1.0)
    parser.add_argument("--lambda_cosine", type=float, default=0.1)
    
    # SNR
    parser.add_argument("--snr_gamma", type=float, default=5.0)
    parser.add_argument("--snr_floor", type=float, default=0.1)
    
    # Optimizer
    parser.add_argument("--optimizer_type", type=str, default="AdamW8bit")
    parser.add_argument("--weight_decay", type=float, default=0.0)
    
    # Scheduler
    parser.add_argument("--lr_scheduler", type=str, default="cosine_with_restarts")
    parser.add_argument("--lr_warmup_steps", type=int, default=100)
    parser.add_argument("--lr_num_cycles", type=int, default=1)
    
    args = parser.parse_args()
    
    # Load config from TOML
    if args.config and os.path.exists(args.config):
        import toml
        config = toml.load(args.config)
        
        model_cfg = config.get("model", {})
        training_cfg = config.get("training", {})
        lora_cfg = config.get("lora", {})
        img2img_cfg = config.get("img2img", {})
        acrf_cfg = config.get("acrf", {})
        
        # Model paths
        args.dit = model_cfg.get("dit", args.dit)
        args.vae = model_cfg.get("vae", args.vae)
        args.output_dir = model_cfg.get("output_dir", args.output_dir)
        
        # Img2Img specific
        args.strength_min = img2img_cfg.get("strength_min", args.strength_min)
        args.strength_max = img2img_cfg.get("strength_max", args.strength_max)
        
        # LoRA
        args.network_dim = lora_cfg.get("network_dim", args.network_dim)
        args.network_alpha = lora_cfg.get("network_alpha", args.network_alpha)
        args.resume_lora = lora_cfg.get("resume_lora", args.resume_lora)
        
        # Training
        args.output_name = training_cfg.get("output_name", args.output_name)
        args.num_train_epochs = training_cfg.get("num_train_epochs", args.num_train_epochs)
        args.learning_rate = training_cfg.get("learning_rate", args.learning_rate)
        args.gradient_accumulation_steps = training_cfg.get("gradient_accumulation_steps", args.gradient_accumulation_steps)
        
        # AC-RF
        args.turbo_steps = acrf_cfg.get("turbo_steps", args.turbo_steps)
        args.shift = acrf_cfg.get("shift", args.shift)
        args.use_dynamic_shift = acrf_cfg.get("use_dynamic_shift", args.use_dynamic_shift)
        args.jitter_scale = acrf_cfg.get("jitter_scale", args.jitter_scale)
        args.enable_turbo = acrf_cfg.get("enable_turbo", args.enable_turbo)
        
        # Loss
        args.lambda_l1 = training_cfg.get("lambda_l1", args.lambda_l1)
        args.lambda_cosine = training_cfg.get("lambda_cosine", args.lambda_cosine)
        args.snr_gamma = training_cfg.get("snr_gamma", args.snr_gamma)
        
        # Optimizer
        args.optimizer_type = training_cfg.get("optimizer_type", args.optimizer_type)
        args.weight_decay = training_cfg.get("weight_decay", args.weight_decay)
    
    return args


def sample_strength(batch_size: int, strength_min: float, strength_max: float, device: torch.device) -> torch.Tensor:
    """
    éšæœºé‡‡æ · strength å€¼ (uniform)
    
    Args:
        batch_size: batch å¤§å°
        strength_min: æœ€å° strength
        strength_max: æœ€å¤§ strength
        device: è®¾å¤‡
        
    Returns:
        (batch_size,) çš„ strength tensor
    """
    return torch.rand(batch_size, device=device) * (strength_max - strength_min) + strength_min


def get_timesteps_from_strength(
    strength: torch.Tensor,
    num_train_timesteps: int = 1000,
) -> torch.Tensor:
    """
    æ ¹æ® strength è®¡ç®—å¯¹åº”çš„ timestep
    
    ä¸ Img2Img Pipeline çš„é€»è¾‘ä¸€è‡´:
    - strength=1.0 -> timestep=1000 (ä»çº¯å™ªå£°å¼€å§‹)
    - strength=0.0 -> timestep=0 (æ— å˜åŒ–)
    
    Args:
        strength: (batch_size,) strength å€¼
        num_train_timesteps: è®­ç»ƒæ€»æ­¥æ•°
        
    Returns:
        (batch_size,) çš„ timestep å€¼
    """
    # t = strength * num_train_timesteps
    return strength * num_train_timesteps


def scale_noise_for_img2img(
    latents: torch.Tensor,
    noise: torch.Tensor,
    strength: torch.Tensor,
) -> torch.Tensor:
    """
    Img2Img ä¸“ç”¨åŠ å™ªæ–¹å¼
    
    ä¸ FlowMatchEulerDiscreteScheduler.scale_noise ä¸€è‡´:
    z_t = (1 - sigma) * latents + sigma * noise
    
    å…¶ä¸­ sigma = strength (åœ¨ [0, 1] èŒƒå›´)
    
    Args:
        latents: æºå›¾åƒ latents (x_0)
        noise: æ ‡å‡†é«˜æ–¯å™ªå£°
        strength: (batch_size,) strength å€¼
        
    Returns:
        åŠ å™ªåçš„ latents
    """
    sigma = strength.view(-1, 1, 1, 1)
    return (1 - sigma) * latents + sigma * noise


def main():
    global _interrupted
    args = parse_args()
    
    # Create output directory
    os.makedirs(args.output_dir, exist_ok=True)
    
    # Initialize Accelerator
    accelerator = Accelerator(
        gradient_accumulation_steps=args.gradient_accumulation_steps,
    )
    
    if args.seed is not None:
        set_seed(args.seed)
    
    # Determine weight dtype
    weight_dtype = torch.float32
    if accelerator.mixed_precision == "fp16":
        weight_dtype = torch.float16
    elif accelerator.mixed_precision == "bf16":
        weight_dtype = torch.bfloat16
    
    logger.info("\n" + "=" * 60)
    logger.info("ğŸ–¼ï¸ Z-Image Img2Img Training")
    logger.info("=" * 60)
    logger.info(f"ğŸ“ è¾“å‡º: {args.output_dir}/{args.output_name}")
    logger.info(f"ğŸ’ª Strength èŒƒå›´: [{args.strength_min}, {args.strength_max}]")
    logger.info(f"âš¡ ç²¾åº¦: {weight_dtype}")
    
    # =========================================================================
    # 1. Load Transformer
    # =========================================================================
    logger.info("\n[1/5] åŠ è½½ Transformer...")
    
    try:
        from zimage_trainer.models.transformer_z_image import ZImageTransformer2DModel
        logger.info("  âœ“ ä½¿ç”¨æœ¬åœ° ZImageTransformer2DModel")
    except ImportError:
        from diffusers import ZImageTransformer2DModel
        logger.warning("  âš  ä½¿ç”¨ diffusers é»˜è®¤ç‰ˆæœ¬")
    
    transformer = ZImageTransformer2DModel.from_pretrained(
        args.dit,
        torch_dtype=weight_dtype,
        local_files_only=True,
    )
    transformer = transformer.to(accelerator.device)
    
    if args.gradient_checkpointing:
        transformer.enable_gradient_checkpointing()
        logger.info("  [CKPT] Gradient checkpointing enabled")
    
    transformer.train()
    
    # =========================================================================
    # 2. Apply LoRA
    # =========================================================================
    logger.info(f"\n[2/5] åˆ›å»º LoRA (rank={args.network_dim})...")
    
    network = LoRANetwork(
        unet=transformer,
        lora_dim=args.network_dim,
        alpha=args.network_alpha,
        multiplier=1.0,
        target_names=ZIMAGE_TARGET_NAMES,
    )
    network.apply_to(transformer)
    
    if args.resume_lora and os.path.exists(args.resume_lora):
        network.load_weights(args.resume_lora)
        logger.info(f"  [RESUME] å·²åŠ è½½ LoRA: {args.resume_lora}")
    
    network.to(accelerator.device, dtype=weight_dtype)
    
    transformer.requires_grad_(False)
    
    trainable_params = []
    for lora_module in network.lora_modules.values():
        trainable_params.extend(lora_module.get_trainable_params())
    
    param_count = sum(p.numel() for p in trainable_params)
    logger.info(f"  âœ“ å‚æ•°é‡: {param_count:,} ({param_count/1e6:.2f}M)")
    
    # =========================================================================
    # 3. Initialize AC-RF Trainer
    # =========================================================================
    logger.info("\n[3/5] åˆå§‹åŒ– AC-RF Trainer...")
    
    use_dynamic_shift = getattr(args, 'use_dynamic_shift', True)
    if isinstance(use_dynamic_shift, str):
        use_dynamic_shift = use_dynamic_shift.lower() in ('true', '1', 'yes')
    
    acrf_trainer = ACRFTrainer(
        num_train_timesteps=1000,
        turbo_steps=args.turbo_steps,
        shift=args.shift,
        use_dynamic_shift=use_dynamic_shift,
    )
    acrf_trainer.verify_setup()
    
    # =========================================================================
    # 4. DataLoader (Img2Img ä¸“ç”¨)
    # =========================================================================
    logger.info("\n[4/5] åŠ è½½æ•°æ®é›†...")
    
    # TODO: å®ç° Img2Img ä¸“ç”¨ DataLoader
    # éœ€è¦åŒæ—¶åŠ è½½ source (æºå›¾) å’Œ target (ç›®æ ‡å›¾)
    logger.warning("  âš  Img2Img DataLoader å°šæœªå®ç°ï¼Œä½¿ç”¨å ä½ç¬¦")
    
    # Placeholder - éœ€è¦å®ç° create_img2img_dataloader
    # dataloader = create_img2img_dataloader(args)
    
    # =========================================================================
    # 5. Optimizer and Scheduler
    # =========================================================================
    logger.info("\n[5/5] é…ç½®ä¼˜åŒ–å™¨...")
    
    if args.optimizer_type == "AdamW8bit":
        try:
            import bitsandbytes as bnb
            optimizer = bnb.optim.AdamW8bit(trainable_params, lr=args.learning_rate, weight_decay=args.weight_decay)
        except ImportError:
            optimizer = torch.optim.AdamW(trainable_params, lr=args.learning_rate, weight_decay=args.weight_decay)
            logger.warning("  âš  bitsandbytes æœªå®‰è£…ï¼Œä½¿ç”¨æ ‡å‡† AdamW")
    else:
        optimizer = torch.optim.AdamW(trainable_params, lr=args.learning_rate, weight_decay=args.weight_decay)
    
    logger.info(f"  âœ“ {args.optimizer_type}, LR={args.learning_rate}")
    
    # =========================================================================
    # Training Loop (æ¡†æ¶)
    # =========================================================================
    logger.info("\n" + "=" * 60)
    logger.info("ğŸš§ Img2Img è®­ç»ƒå¾ªç¯æ¡†æ¶å·²å‡†å¤‡")
    logger.info("=" * 60)
    
    # è®­ç»ƒå¾ªç¯çš„å…³é”®æ­¥éª¤:
    # 1. åŠ è½½ source_latents (æºå›¾ VAE encode)
    # 2. åŠ è½½ target_latents (ç›®æ ‡å›¾ VAE encode)
    # 3. éšæœºé‡‡æ · strength å€¼
    # 4. ä½¿ç”¨ scale_noise_for_img2img åŠ å™ª
    # 5. è®¡ç®—å¯¹åº”çš„ timestep
    # 6. Transformer forward
    # 7. è®¡ç®— loss: pred vs (noise - source_latents)
    
    """
    è®­ç»ƒä¼ªä»£ç :
    
    for batch in dataloader:
        source_latents = batch['source_latents']  # æºå›¾
        target_latents = batch['target_latents']  # ç›®æ ‡å›¾
        vl_embed = batch['vl_embed']
        
        batch_size = source_latents.shape[0]
        noise = torch.randn_like(target_latents)
        
        # éšæœºé‡‡æ · strength
        strength = sample_strength(batch_size, args.strength_min, args.strength_max, device)
        
        # Img2Img åŠ å™ªæ–¹å¼
        noisy_latents = scale_noise_for_img2img(target_latents, noise, strength)
        
        # è®¡ç®— timestep (ä¸ Pipeline ä¸€è‡´)
        timesteps = get_timesteps_from_strength(strength, 1000)
        
        # ç›®æ ‡æ˜¯ä» noisy_latents é¢„æµ‹ velocity (noise - target_latents)
        target_velocity = noise - target_latents
        
        # Forward pass
        model_pred = transformer(noisy_latents, timesteps, vl_embed)
        
        # è®¡ç®— loss
        loss = F.l1_loss(model_pred, target_velocity)
    """
    
    logger.info("\nâœ… Img2Img è®­ç»ƒè„šæœ¬æ¡†æ¶åˆ›å»ºå®Œæˆ")
    logger.info("ä¸‹ä¸€æ­¥: å®ç° Img2Img DataLoader")


if __name__ == "__main__":
    main()
